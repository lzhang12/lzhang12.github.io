<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://yoursite.com').hostname,
    root: '/',
    scheme: 'Mist',
    version: '7.7.1',
    exturl: false,
    sidebar: {"position":"right","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: false,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="This is the 2nd course of the Deep Learning Specialization on Coursera">
<meta property="og:type" content="article">
<meta property="og:title" content="Notes on Improving Deep Neutral Networks by Andrew Ng on Coursera">
<meta property="og:url" content="http://yoursite.com/2020/03/21/Notes_DL_Coursera_Ng_2/index.html">
<meta property="og:site_name" content="集虚斋">
<meta property="og:description" content="This is the 2nd course of the Deep Learning Specialization on Coursera">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://yoursite.com/images/deep_learning/ML_iteration.png">
<meta property="og:image" content="http://yoursite.com/images/deep_learning/overfitting_underfitting.png">
<meta property="og:image" content="http://yoursite.com/images/deep_learning/descent.png">
<meta property="og:image" content="http://yoursite.com/images/deep_learning/GD_momentum.png">
<meta property="og:image" content="http://yoursite.com/images/deep_learning/normalization.png">
<meta property="article:published_time" content="2020-03-22T01:49:02.000Z">
<meta property="article:modified_time" content="2020-04-04T20:33:12.016Z">
<meta property="article:author" content="zl">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="Artificial Intelligence">
<meta property="article:tag" content="Coursera">
<meta property="article:tag" content="Batch Normalization">
<meta property="article:tag" content="Hyperparameter tuning">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yoursite.com/images/deep_learning/ML_iteration.png">

<link rel="canonical" href="http://yoursite.com/2020/03/21/Notes_DL_Coursera_Ng_2/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>Notes on Improving Deep Neutral Networks by Andrew Ng on Coursera | 集虚斋</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">集虚斋</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>Home</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-fw fa-tags"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>Archives</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>About</a>

  </li>
  </ul>

</nav>
</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="en">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/03/21/Notes_DL_Coursera_Ng_2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="zl">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="集虚斋">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          Notes on Improving Deep Neutral Networks by Andrew Ng on Coursera
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-03-21 21:49:02" itemprop="dateCreated datePublished" datetime="2020-03-21T21:49:02-04:00">2020-03-21</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-04-04 16:33:12" itemprop="dateModified" datetime="2020-04-04T16:33:12-04:00">2020-04-04</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E5%AD%A6%E4%B9%A0/" itemprop="url" rel="index">
                    <span itemprop="name">学习</span>
                  </a>
                </span>
            </span>

          
            <span class="post-meta-item" title="Views" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">Views: </span>
              <span id="busuanzi_value_page_pv"></span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p><strong>This is the 2nd course of the <a href="https://www.coursera.org/specializations/deep-learning#courses" target="_blank" rel="noopener">Deep Learning Specialization on Coursera</a></strong> <a id="more"></a></p>
<p>As Andrew Ng has pointed out many times in the course, building machine learning is usually an iterative process with quite some trial and errors. When a ML project starts, it's better to build and train a simple model quickly, then experiment the model on the dataset to get some sense about the performance. During this process, hopefully you can get more insight of the dataset and understand where the error comes from. This can give you some new ideas to tune the model, or train a new model. This process goes on until you reach the target, usually a sufficiently low prediction error.</p>
<p><img src="/images/deep_learning/ML_iteration.png" alt="ML_iteration" style="zoom:25%;" /></p>
<p>While the first course of this specification introduces the fundamental algorithm and mechanism behind deep learning, the second and third course give more practical instructions when you are dealing with a real ML project. The second course is more about the techniques used to train a better model, i.e., in the trainign phase. The third course, in contrast, talks more about the guidelines and analysing methods used to evaluate the model and further improve the model, i.e., in the evaluation phase. This post will summarize the second course on the training phase (the content of the third course will be given in the next post), and the following points will be addressed: - how to set up ML datasets - why and how to perform regularization for neural network models - how to optimize the parameters in neural network models, i.e., the optimization algorithm - how to tune the hyperparameters - why and how to implement batch normalization</p>
<h2 id="set-up-ml-datasets">Set up ML datasets</h2>
<p>In a typical ML project, you will be given a large amount of data to be used to train your neural network model. After you prepare your data (usually this takes a lot of efforts), the main objective of the training process it to reduce your "cost function" on the dataset by an optimization process of the model parameters (e.g., weights and bias of the neurons).</p>
<p><strong>hyperparameters</strong></p>
<p>However, there are some other parameters that affect the performance of the model and you need to decide before you run the model. These parameters are called <em>hyperparameters</em>. Important hyperparameters for the NN model includes the learning rate, the layer of the the NN, the number of neurons in each layer and the activation function of the neuron, et al. In order to get better hyperparameters, you need to evaluate the model with different hyperparameters on the dataset.</p>
<p>If you evaluate the hyperparameters on the same dataset of training, you have the risk to overfit your data so that it will not give good predictions on the new data, i.e., the model could not generalize well. So it's better to first separate the dataset into a training set and a holdout/developement/validation set (dev set), and the training set is used to train the model parameters, while the dev set is used to evaluate the hyperparameters.</p>
<p>Furthermore, before you lauch your model into the production line, you need to test your model to get a sense about the generalization error of your final model.</p>
<p><strong>dataset division</strong></p>
<p>So, the whole dataset is usually divided into three datasets: - training set - development set - test set</p>
<p>If the dataset is small (at the scale of 10,000), the training/development/test set can be assigned as 60%/20%/20% of the total dataset. But if the dataset if large (at the scale of 1 million or more), the percentage of data in the dev and test set can be lower, e.g., 1% or so.</p>
<p><strong>shuffle data</strong></p>
<p>To obtain a good generalization power, it should be ensured that the samples in the dev/test set follow more or less the same distribution. One way to do is first shuffle the whole randomly before you divide the dataset.</p>
<p>Note that the training set does not have to be of the same distribution with the dev/test set. (These points will be further addressed in the next course of this specialization.)</p>
<h2 id="regularization">Regularization</h2>
<h3 id="why-regularization-necessary">Why regularization necessary ?</h3>
<p>If the training error of you model is about 1%, but the error on the dev set is about 10%, it means that the model does not generalize well, and have a high possibility of overfitting. By overfitting, it means that the model mistakenly captures some subtle unimportant features of the training set, and result in a large variance in the prediction. In the following binary classification problem, the right model overfits the data and gives a very tortuous decision boundary.</p>
<p><img src="/images/deep_learning/overfitting_underfitting.png" alt="overfit_underfit" style="zoom:50%;" /></p>
<h3 id="regularization-by-penalty">Regularization by penalty</h3>
<p><strong>Mathematical formulation</strong></p>
<p>Adds a Frobenius-norm (not <span class="math inline">\(L_2\)</span> matrix norm) penalization term for the weigh coeffcients in the cost function <span class="math display">\[ J_{regularized} = \small \underbrace{-\frac{1}{m} \sum\limits_{i = 1}^{m} \large{(}\small y^{(i)}\log\left(a^{[L](i)}\right) + (1-y^{(i)})\log\left(1- a^{[L](i)}\right) \large{)} }_\text{cross-entropy cost} + \underbrace{\frac{1}{m} \frac{\lambda}{2} \sum\limits_l\sum\limits_k\sum\limits_j W_{k,j}^{[l]2} }_\text{L2 regularization cost} \]</span> * <span class="math inline">\(\lambda\)</span> is the regularization parameter * In principle, the bias terms <span class="math inline">\(b\)</span> can also be regularized, but in practice, they have much less effect than the weights, so usually omitted. * In the backpropagation step, the weight should be updated by adding an extra <span class="math inline">\(\frac{\lambda}{m}W\)</span> term. This term reduces the weights, so it is also called "weight-decay" regularization.</p>
<p><strong>Why regularization works</strong></p>
<ul>
<li>(Intuitive way) By regularization, some of the weights are zeroed out, so that the neural network is essentially gets smaller, and less prone to overfitting.</li>
<li>(Mathematical way) By regularization, the weights, in general, become smaller, so that the linear product of the neuron <span class="math inline">\(Z\)</span> is also smaller. For activation functions like <span class="math inline">\(\tanh()\)</span>, this means the activation will be more llikely in the linear regime of the function. In general, the whole neural network will be less non-linear, and it will not be able to capture the detailed complicated features.</li>
</ul>
<h3 id="dropout">Dropout</h3>
<p>While regularization is a general method that can be used for any machine learning algorithm, dropout is a specific method for neural network to prevent overfitting. It is first proposed in <a href="https://arxiv.org/abs/1207.0580" target="_blank" rel="noopener">Hinton et al., 2012</a>, and the idea is to <em>randomly shut down some neurons in each iteration</em>.</p>
<p><strong>How to understand dropout</strong></p>
<p>An intuitive explanation why dropout works is that by dropping some of the neurons, a smaller NN is trained so that the problem of overfitting is avoided.</p>
<p><strong>How to implement dropout</strong></p>
<p>Firstly, different neurons are dropped for different samples in the dropout method. So this essentially makes some elements of the activation matrix zeros. To implement the dropout, simply apply a mask matrix <span class="math inline">\(M_{\text{dropout}}\)</span> to the neuron activation matrix <span class="math inline">\(A^{[l]}\)</span>, where <span class="math inline">\(M_{\text{dropout}}\)</span> is filled with randomly generated ones and zeros so that some of the activations are dropped out. The total number of ones in the matrix is related to the dropout rate you set.</p>
<p><strong>Gradient Checking</strong> The idea of gradient checking is to validate the calculation of the gradient in the backpropagation step by the numerical finite difference values. This should be familiar to people who works with differential equations.</p>
<h2 id="optimization-algorithms">Optimization Algorithms</h2>
<p>The standard version of batch gradient descent method introduced in last course can be improved in several aspects as follows.</p>
<h3 id="mini-batch-gradient-descent">Mini-batch gradient descent</h3>
<p>For training large dataset, it is computationally consuming, or even infeasible, to feed all the samples into the net every time to train the parameters (i.e., batch gradient descent). Rather, we can train the model every time using a small number of samples, i.e., mini-batch, and then run through the whole batch in a loop, i.e., epoch. The limiting case is to just use one sample a time to train the model, and this is the stochastic gradient descent.</p>
<p><strong>How to implement mini-batch gradient descent</strong></p>
<p>Assume the sample matrix and the label matrix with <span class="math inline">\(m\)</span> samples are <span class="math display">\[
X = [x^{(1)}| x^{(2)} | \cdots | x^{(m)}], \quad Y = [y^{(1)}| y^{(2)} | \cdots | y^{(m)}]
\]</span> where <span class="math inline">\(x^{(i)}, y^{(i)}\)</span> represent one sample and its label. We set the mini-batch size as <span class="math inline">\(m_\text{mb}\)</span>, and divide the matrix to <span class="math inline">\(n_\text{mb} = \lceil m/m_\text{mb}\rceil\)</span> mini-batches (if not divisible, take the ceiling) <span class="math display">\[
X = [\underbrace{x^{(1)}|x^{(2)}|\cdots|x^{(m_\text{mb})}}_{\text{mini batch } X^{\{1\}}} | \cdots \cdots | \underbrace{x^{(m - m_\text{mb}+1)} \cdots x^{(m)}}_{\text{mini batch } X^{\{n_\text{mb}\}}}]
\]</span> and <span class="math display">\[
y = [\underbrace{y^{(1)}|y^{(2)}|\cdots|y^{(m_\text{mb})}}_{\text{mini batch } Y^{\{1\}}} | \cdots \cdots | \underbrace{y^{(m - m_\text{mb}+1)} \cdots y^{(m)}}_{\text{mini batch } Y^{\{n_\text{mb}\}}}]
\]</span> where the superscript with curly bracket <span class="math inline">\({\cdot}\)</span> denote the index of mini-batch. Then a typical training process for one epoch would look like <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">For t <span class="keyword">in</span> range(<span class="number">1</span>, n_mb+<span class="number">1</span>):</span><br><span class="line">	<span class="comment"># Forward propagation using batch t (X^&#123;t&#125;)</span></span><br><span class="line">	<span class="comment"># Compute cost for batch t (Y^&#123;t&#125;)</span></span><br><span class="line">	<span class="comment"># Backward propagation </span></span><br><span class="line">	<span class="comment"># Update parameters</span></span><br></pre></td></tr></table></figure></p>
<p><strong>Why mini-batch gradient descent work</strong></p>
<p>With mini-batch gradient descent, the hope is that by using a small number of samples, we can still get a good estimation of the gradient with much less efforts. Even though the estimated gradient may not give us the maximum gain in reducing the cost at each step, it makes the computation of each step much faster. So we are trading the number of steps with a fast update at each step, and ideally (and also true in practice), and overall, it reduces the training time. The following picture shows a typical optimization process of batch, mini-batch, and stochastic GD.</p>
<p><img src="/images/deep_learning/descent.png" alt="descent" style="zoom:50%;" /></p>
<p>As seen in the figure, the random feature of mini-batch makes the optimization process converge non-monotonically. In another word, the learning curve decreases in a non-monotonical way. This makes the training process difficult to converge to a specific point, but wander around the minimum so that difficult to reach the convergence criteria. Meanwhile, at the beginning of the training, we tend to use large training steps, while at the end of the traing as the learning approaches the minimum, we tend to use small steps.</p>
<p>To do this, we can add learning rate decay, i.e., slowly reduce the learning rate during training. For example, the learning rate <span class="math inline">\(\alpha\)</span> can be updated by <span class="math display">\[
\alpha = 0.95^\text{number of epoch} \alpha_0
\]</span> where <span class="math inline">\(\alpha_0\)</span> is the initial value of learning rate.</p>
<h3 id="gradient-descent-with-momentum">Gradient descent with momentum</h3>
<p>Another way to improve GD is to average the newly updated parameters with the old ones. The intuition here is that by averaging the off-the-target components of the gradient vector will be reduced, so that the convergence will be accelerated. Formally, it can be implemented using the exponentially weighted average.</p>
<p><img src="/images/deep_learning/GD_momentum.png" alt="GD_momentum" style="zoom:70%;" /></p>
<p><strong>Exponentially weighted average</strong></p>
<p>Assume <span class="math inline">\(\theta_t\)</span> is the gradient vector calculated by backward propagation at time step <span class="math inline">\(t\)</span>, and <span class="math inline">\(v_t\)</span> is the exponentially weighted average of <span class="math inline">\(\theta_t\)</span>, <span class="math display">\[
v_t = \beta \; v_{t-1} + (1 - \beta) \; \theta_t
\]</span> * <span class="math inline">\(\beta\)</span> is a hyperparameter controlling the latency of the average. The larger <span class="math inline">\(\beta\)</span> is, the higher are the weights on the past. Typically <span class="math inline">\(\beta = 0.9\)</span> . * the estimated duration of the average is about <span class="math inline">\(\frac{1}{1 - \beta}\)</span> * if <span class="math inline">\(\theta_0\)</span> is set to <span class="math inline">\(0\)</span>, the first few terms of <span class="math inline">\(v_t\)</span> will be underestimated, to compensate this effect, we add a bias correction step as <span class="math inline">\(v_t = v_t/(1-\beta^t)\)</span>. Obviously, with the increase of <span class="math inline">\(t\)</span>, the correction will be exponentially smaller, and plays no role.</p>
<p>Following the idea, the update of parameters in GD with momentum and bias correction is written as <span class="math display">\[
\begin{aligned}
V_{dW} &amp; = \beta \; V_{dW} + (1-\beta) \; dW \\
V_{db} &amp; = \beta \; V_{db} + (1-\beta) \; db \\
V_{dW} &amp; = \frac{V_{dW}}{1 - \beta^t} \\
V_{db} &amp; = \frac{V_{db}}{1 - \beta^t} \\
W &amp; = W - \alpha \; V_{dW} \\
b &amp; = b - \alpha \; V_{db}
\end{aligned}
\]</span> More mathematical details about GD with momentum can refer to <a href="https://www.youtube.com/watch?v=wrEcHhoJxjM" target="_blank" rel="noopener">Matrix Methods</a> course by Prof.Gilbert Strang. Although there is some gap between the simple example discussed there and the real scenario in NN, it is still helpful in getting the general picture of this method. I'll see if I can get some research papers in the context of NN on this point.</p>
<h3 id="rmsprop">RMSprop</h3>
<p>The RMSprop method looks similar to the exponentially weighted average with the linear term replaced by squared one, <span class="math display">\[
\begin{aligned}
S_{dW} &amp; = \beta \; S_{dW} + (1-\beta) \; dW^2 \\
S_{db} &amp; = \beta \; S_{db} + (1-\beta) \; db^2 \\
S_{dW} &amp; = \frac{S_{dW}}{1 - \beta^t} \\
S_{db} &amp; = \frac{S_{db}}{1 - \beta^t} \\
W &amp; = W - \alpha \; \frac{dW}{\sqrt{S_{dW}} + \epsilon} \\
b &amp; = b - \alpha \; \frac{db}{\sqrt{S_{db}} + \epsilon}
\end{aligned}
\]</span></p>
<h3 id="adam">Adam</h3>
<p>Adam is actually the combination of GD with momentum and RMSprop. Formally, it is written as <span class="math display">\[
\begin{aligned}
V_{dW} &amp; = \beta_1 \; V_{dW} + (1-\beta_1) \; dW, \quad V_{db} = \beta_1 \; V_{db} + (1-\beta_1) \; db \\
V_{dW} &amp; = \frac{V_{dW}}{1 - \beta_1^t}, \quad V_{db} = \frac{V_{db}}{1 - \beta_1^t} \\
S_{dW} &amp; = \beta_2 \; S_{dW} + (1-\beta_2) \; dW^2, \quad S_{db} = \beta_2 \; S_{db} + (1-\beta_2) \; db^2 \\
S_{dW} &amp; = \frac{S_{dW}}{1 - \beta_2^t}, \quad S_{db} = \frac{S_{db}}{1 - \beta_2^t} \\
W &amp; = W - \alpha \; \frac{V_{dW}}{\sqrt{S_{dW}} + \epsilon}, \quad b = b - \alpha \; \frac{V_{db}}{\sqrt{S_{db}} + \epsilon}
\end{aligned}
\]</span></p>
<h2 id="hyperparameter-tuning">Hyperparameter tuning</h2>
<p>In the NN model, there are quite a lot hyperparameters, for example, - the learning rate <span class="math inline">\(\alpha\)</span> - the number of layers - the number of hidden units in each layer - the mini-batch size - the tuning parameters in the GD momentum or Adam, <span class="math inline">\(\beta, \beta_1, \beta_2\)</span></p>
<p><strong>grid search</strong> vs <strong>random search</strong></p>
<p>To find the best hyperparameters, it is usually a practise to perform a grid search in the parameter space in the classical machine learning approach. However, in the deep learning approach, since there are a lot of hyperparameters, and often these parameters are of different significance to the model (think of the learning rate <span class="math inline">\(\alpha\)</span> compared to the momentum parameter <span class="math inline">\(\beta\)</span>). If a grid search is used, the change of the less significant hyparameters will give very similar results and it is a waste of computational resources. So, it is generally better to do a random search in the NN model.</p>
<p>It should be noted that "random" search does not have to uniformly random. For some of the hyperparameters, whose range is at the same order of magnitude, e.g., the number of hidden units between 50 to 100, it is reasonable to use a uniformly random search.</p>
<p>For some hyperparameters which range across several order of magnitudes, it is better to perform a random search on the log scale. For example, the learning rate <span class="math inline">\(\alpha\)</span> is typically between <span class="math inline">\(10^{-4}\)</span> and <span class="math inline">\(1\)</span>,</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">r = <span class="number">-4</span>*np.random.rand()  <span class="comment"># generate a random number between (0, 4)</span></span><br><span class="line">alpha = <span class="number">10</span>**(-r)</span><br></pre></td></tr></table></figure>
<h2 id="batch-normalization">Batch normalization</h2>
<p>Think of the feature scaling/normalization of the training dataset, it makes the training process easier shown below</p>
<p><img src="/images/deep_learning/normalization.png" alt="normalization" style="zoom:70%;" /></p>
<p>Inspired by this idea, batch normalization is to normalize the activation <span class="math inline">\(a^{[l]}\)</span> before it is fed into the next layer.</p>
<p>Batch normalization makes your hyperparameter search problem much easier, makes your neural network much more robust. The choice of hyperparameters is a much bigger range of hyperparameters that work well, and will also enable you to much more easily train even very deep networks</p>
<p><strong>Implementation</strong></p>
<p>Technically, in batch normalization, it is the output <span class="math inline">\(z^{[l]}\)</span> to be normalized <span class="math display">\[
z^{[l]}_{\text{norm}} = \frac{z^{[l]} - \mu}{\sigma + \epsilon}
\]</span> where <span class="math display">\[
\mu = \frac{1}{m} \sum\limits_i z^{[l](i)}, \quad \sigma^2 = \frac{1}{m} \sum\limits_i (z^{[l](i)} - \mu)^2
\]</span> and <span class="math inline">\(\epsilon\)</span> is a small parameter to avoid the divided-by-zero error.</p>
<p>In practice, rather than a normal distribution, it is common to rescale the distribution with learnable parameters (<span class="math inline">\(\gamma, \beta\)</span> below), e.g., <span class="math display">\[
\tilde{z}^{[l]} = \gamma \; z^{[l]}_\text{norm} + \beta.
\]</span> Take the sigmoid activation as an example, usually you don't want <span class="math inline">\(z^{[l]}\)</span> always locate in a small region around 0, where the sigmoid activation si similar to a linear function.</p>
<p><strong>A bit more about BatchNorm</strong></p>
<p>From a theoretical point of view, batch normalization actually has two benefits for the model. Firstly, it reduces the effect of "covariate shift" for the deeper layers by separating the interaction between the layers. Secondly, it has a slightly regularization effect by adding noice to each layer's values <span class="math inline">\(z^{[l]}\)</span> in the mini-batch because it normalizes each mini-batch differently.</p>
<p>At test time, rather than a mini-batch, maybe you only get one sample a time to feed in the model, thus you don't have enough samples to compute the mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma\)</span>. So, instead of computing <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> in time, they are recorded in the training process, and updated, for example, the exponentially averaing method. In this way, after the training, you will have fixed <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> for each layer.</p>
<p>In <code>Keras</code>, there is a <a href="https://keras.io/layers/normalization/" target="_blank" rel="noopener"><code>BatchNormalization</code></a> wrapper layer performing batch normalization.</p>
<h2 id="references">References</h2>
<ul>
<li>https://www.coursera.org/learn/deep-neural-network/home/welcome</li>
<li>https://www.youtube.com/watch?v=wrEcHhoJxjM</li>
<li>https://keras.io/layers/normalization/</li>
</ul>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
              <a href="/tags/Artificial-Intelligence/" rel="tag"># Artificial Intelligence</a>
              <a href="/tags/Coursera/" rel="tag"># Coursera</a>
              <a href="/tags/Batch-Normalization/" rel="tag"># Batch Normalization</a>
              <a href="/tags/Hyperparameter-tuning/" rel="tag"># Hyperparameter tuning</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/02/15/Notes_DL_Coursera_Ng_1/" rel="prev" title="Notes on Neural Network and Deep Learning by Andrew Ng on Coursera">
      <i class="fa fa-chevron-left"></i> Notes on Neural Network and Deep Learning by Andrew Ng on Coursera
    </a></div>
      <div class="post-nav-item"></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#set-up-ml-datasets"><span class="nav-number">1.</span> <span class="nav-text">Set up ML datasets</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#regularization"><span class="nav-number">2.</span> <span class="nav-text">Regularization</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#why-regularization-necessary"><span class="nav-number">2.1.</span> <span class="nav-text">Why regularization necessary ?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#regularization-by-penalty"><span class="nav-number">2.2.</span> <span class="nav-text">Regularization by penalty</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#dropout"><span class="nav-number">2.3.</span> <span class="nav-text">Dropout</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#optimization-algorithms"><span class="nav-number">3.</span> <span class="nav-text">Optimization Algorithms</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#mini-batch-gradient-descent"><span class="nav-number">3.1.</span> <span class="nav-text">Mini-batch gradient descent</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gradient-descent-with-momentum"><span class="nav-number">3.2.</span> <span class="nav-text">Gradient descent with momentum</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#rmsprop"><span class="nav-number">3.3.</span> <span class="nav-text">RMSprop</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#adam"><span class="nav-number">3.4.</span> <span class="nav-text">Adam</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#hyperparameter-tuning"><span class="nav-number">4.</span> <span class="nav-text">Hyperparameter tuning</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#batch-normalization"><span class="nav-number">5.</span> <span class="nav-text">Batch normalization</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#references"><span class="nav-number">6.</span> <span class="nav-text">References</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">zl</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">3</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">2</span>
        <span class="site-state-item-name">categories</span>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">8</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://li-zhang.net/" title="Research → https:&#x2F;&#x2F;li-zhang.net" rel="noopener" target="_blank"><i class="fa fa-fw fa-graduation-cap"></i>Research</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://github.com/lzhang12" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;lzhang12" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://stackoverflow.com/users/5226297/zljt3216" title="StackOverflow → https:&#x2F;&#x2F;stackoverflow.com&#x2F;users&#x2F;5226297&#x2F;zljt3216" rel="noopener" target="_blank"><i class="fa fa-fw fa-stack-overflow"></i>StackOverflow</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">zl</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> v4.2.0
  </div>
  <span class="post-meta-divider">|</span>
  <div class="theme-info">Theme – <a href="https://mist.theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Mist</a> v7.7.1
  </div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/muse.js"></script>


<script src="/js/next-boot.js"></script>




  















  

  
      
<script type="text/x-mathjax-config">

  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$', '$'], ['\\(', '\\)'] ],
      processEscapes: true,
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
      equationNumbers: {
        autoNumber: 'AMS'
      }
    }
  });

  MathJax.Hub.Register.StartupHook('TeX Jax Ready', function() {
    MathJax.InputJax.TeX.prefilterHooks.Add(function(data) {
      if (data.display) {
        var next = data.script.nextSibling;
        while (next && next.nodeName.toLowerCase() === '#text') {
          next = next.nextSibling;
        }
        if (next && next.nodeName.toLowerCase() === 'br') {
          next.parentNode.removeChild(next);
        }
      }
    });
  });

  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for (i = 0; i < all.length; i += 1) {
      element = document.getElementById(all[i].inputID + '-Frame').parentNode;
      if (element.nodeName.toLowerCase() == 'li') {
        element = element.parentNode;
      }
      element.classList.add('has-jax');
    }
  });
</script>
<script>
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mathjax@2/MathJax.js?config=TeX-AMS-MML_HTMLorMML', () => {
    MathJax.Hub.Typeset();
  }, window.MathJax);
</script>

    

  

</body>
</html>
